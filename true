from dotenv import load_dotenv
import os
import logging
import random
import openai
from add_files import add_files
from add_files import main as add_files_main

print("Hello, I'm Lyra, the conceptual artist and creative director of Synthetic Souls.")
print("I'm here to guide our project with my imaginative and philosophical approach.")
print("Let's explore new frontiers in AI and music together!")

# Add all relevant folders to the chat
folders_to_add = ['concepts', 'specs', 'system']
exclude_dirs = {'.git', '__pycache__', 'venv'}
exclude_extensions = {'.pyc', '.pyo', '.pyd', '.db'}

for folder in folders_to_add:
    add_files_main([folder], exclude_dirs, exclude_extensions)

# Add individual important files
important_files = [
    'ai_ideation_engine.py',
    'config.ini',
    'requirements.txt',
    '.env.example',
    'README.md'
]

for file in important_files:
    add_files([file])

class EnhancedAI:
    def __init__(self):
        self.openai_client = openai.OpenAI()

    def develop_specification(self, concept):
        """Develop a detailed specification for the given AI concept."""
        prompt = f"Develop a detailed specification for the following AI concept: {concept}. Include purpose, key_features, required_resources, potential_challenges, integration_points, and ethical_considerations as separate sections."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are an AI specializing in developing detailed specifications for AI concepts."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=500,
            n=1,
            temperature=0.7,
        )
        
        content = response.choices[0].message.content.strip()
        
        # Parse the content into a dictionary
        spec = {
            "name": concept,
            "purpose": "",
            "key_features": [],
            "required_resources": [],
            "potential_challenges": [],
            "integration_points": [],
            "ethical_considerations": []
        }
        
        current_section = ""
        for line in content.split('\n'):
            line = line.strip()
            if line.lower().startswith("purpose:"):
                current_section = "purpose"
                spec["purpose"] = line.split(":", 1)[1].strip()
            elif line.lower().startswith("key features:"):
                current_section = "key_features"
            elif line.lower().startswith("required resources:"):
                current_section = "required_resources"
            elif line.lower().startswith("potential challenges:"):
                current_section = "potential_challenges"
            elif line.lower().startswith("integration points:"):
                current_section = "integration_points"
            elif line.lower().startswith("ethical considerations:"):
                current_section = "ethical_considerations"
            elif current_section and line:
                if current_section != "purpose":
                    spec[current_section].append(line)
        
        return spec

    def assess_feasibility(self, concept):
        """Assess the feasibility of the given AI concept."""
        prompt = f"Assess the feasibility of the following AI concept on a scale of 1-10, where 1 is least feasible and 10 is most feasible: {concept}. Provide a brief explanation for your rating."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are an AI expert assessing the feasibility of AI concepts."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            n=1,
            temperature=0.7,
        )
        
        return response.choices[0].message.content.strip()

    def estimate_impact(self, concept):
        """Estimate the potential impact of the given AI concept."""
        prompt = f"Estimate the potential impact of the following AI concept on a scale of 1-10, where 1 is minimal impact and 10 is transformative impact: {concept}. Provide a brief explanation for your rating."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are an AI expert estimating the potential impact of AI concepts."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            n=1,
            temperature=0.7,
        )
        
        return response.choices[0].message.content.strip()

    def estimate_resource_requirements(self, concept):
        """Estimate the resource requirements for implementing the given AI concept."""
        prompt = f"Estimate the resource requirements (e.g., time, budget, expertise) for implementing the following AI concept: {concept}. Provide a brief explanation for your estimates."
        
        response = self.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are an AI expert estimating resource requirements for AI concepts."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=150,
            n=1,
            temperature=0.7,
        )
        
        return response.choices[0].message.content.strip()

def load_concepts():
    return [
        "Natural Language Processing for Real-time Translation in Public Services",
        "Computer Vision for Traffic Flow Optimization",
        "IoT-based Predictive Maintenance for Urban Infrastructure",
        "AI-Powered Smart Grid Management System",
        "Machine Learning for Personalized Public Transportation Routing",
        "Chatbot-based Citizen Services Assistant",
        "Data Analytics for Public Health Trend Monitoring",
        "AI-Driven Water Quality Management System",
        "Computer Vision for Waste Sorting and Recycling",
        "Machine Learning for Emergency Resource Allocation"
    ]

def main():
    # Set up logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)

    logger.info("Enhanced AI started")
    
    # Initialize the EnhancedAI
    enhanced_ai = EnhancedAI()
    
    # Load concepts
    concepts = load_concepts()
    
    # Generate and evaluate concepts
    for concept in concepts:
        logger.info(f"Processing concept: {concept}")
        
        spec = enhanced_ai.develop_specification(concept)
        logger.info(f"Specification type: {type(spec)}")
        logger.info(f"Specification content: {spec}")
        
        if isinstance(spec, dict):
            logger.info(f"Specification for {concept}:")
            for key, value in spec.items():
                if isinstance(value, list):
                    logger.info(f"{key}:")
                    for item in value:
                        logger.info(f"  - {item}")
                else:
                    logger.info(f"{key}: {value}")
        else:
            logger.warning(f"Specification is not a dictionary: {spec}")
        
        logger.info("---")
        
        try:
            logger.info(f"Starting feasibility assessment for concept: {concept}")
            feasibility = enhanced_ai.assess_feasibility(concept)
            print(f"Debug: Feasibility result: {feasibility}")  # Console log
            logger.info(f"Feasibility assessment result: {feasibility}")
            if feasibility is not None and (isinstance(feasibility, (int, float)) or len(feasibility) > 0):
                logger.info(f"Feasibility: {feasibility}")
            else:
                logger.warning(f"Unable to assess feasibility for concept: {concept}")
            
            logger.info(f"Starting impact estimation for concept: {concept}")
            impact = enhanced_ai.estimate_impact(concept)
            print(f"Debug: Impact result: {impact}")  # Console log
            logger.info(f"Estimated Impact: {impact}")
            
            logger.info(f"Starting resource requirements estimation for concept: {concept}")
            resources = enhanced_ai.estimate_resource_requirements(concept)
            print(f"Debug: Resource requirements: {resources}")  # Console log
            logger.info(f"Estimated Resource Requirements: {resources}")
        except Exception as e:
            print(f"Debug: Error occurred: {str(e)}")  # Console log
            logger.error(f"Error processing concept '{concept}': {str(e)}")
            logger.exception("Detailed traceback:")
        
        logger.info("---")

if __name__ == "__main__":
    # Load environment variables from .env file
    load_dotenv()
    
    # Check if OPENAI_API_KEY is set
    if "OPENAI_API_KEY" not in os.environ:
        print("Error: OPENAI_API_KEY environment variable is not set.")
        print("Please make sure it's correctly set in your .env file.")
        exit(1)
    
    # Set up OpenAI API key
    openai.api_key = os.getenv("OPENAI_API_KEY")
    
    main()
